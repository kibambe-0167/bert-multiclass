{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithunkumarsr/CodeMixingDravidianLanguage/blob/main/TamilCMD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEyEcB2A4dmA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "\n",
        "from sklearn.metrics import accuracy_score,classification_report, f1_score\n",
        "from sklearn.model_selection import cross_val_score, train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uS6kc4z_8qa"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGgxWSNw42U2",
        "outputId": "8526f855-8ec5-4e3b-a1f2-9ef9e4d11947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# DATA CLEANING AND PREPARATION #\n",
        "class Utils(object):\n",
        "\n",
        "    def cleanText(self, text):\n",
        "        review = re.sub(r\"^https://t.co/[a-zA-Z0-9]*\\s\", \" \", str(text))\n",
        "        review = re.sub(r\"\\([\\s\\S]*\\)\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*\\s\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*$\", \" \", str(review))\n",
        "        review = review.lower()\n",
        "        review = re.sub(r\"that's\", \"that is\", str(review))\n",
        "        review = re.sub(r\"there's\", \"there is\", str(review))\n",
        "        review = re.sub(r\"what's\", \"what is\", str(review))\n",
        "        review = re.sub(r\"where's\", \"where is\", str(review))\n",
        "        review = re.sub(r\"it's\", \"it is\", str(review))\n",
        "        review = re.sub(r\"who's\", \"who is\", str(review))\n",
        "        review = re.sub(r\"i'm\", \"i am\", str(review))\n",
        "        review = re.sub(r\"she's\", \"she is\", str(review))\n",
        "        review = re.sub(r\"he's\", \"he is\", str(review))\n",
        "        review = re.sub(r\"they're\", \"they are\", str(review))\n",
        "        review = re.sub(r\"who're\", \"who are\", str(review))\n",
        "        review = re.sub(r\"ain't\", \"am not\", str(review))\n",
        "        review = re.sub(r\"wouldn't\", \"would not\", str(review))\n",
        "        review = re.sub(r\"shouldn't\", \"should not\", str(review))\n",
        "        review = re.sub(r\"can't\", \"can not\", str(review))\n",
        "        review = re.sub(r\"couldn't\", \"could not\", str(review))\n",
        "        review = re.sub(r\"won't\", \"will not\", str(review))\n",
        "        review = re.sub(r\" pm \", \" \", str(review))\n",
        "        review = re.sub(r\" am \", \" \", str(review))\n",
        "        review = re.sub(r'[^\\[\\]]+(?=\\])', \" \", str(review))\n",
        "        review = re.sub(r\"\\W\", \" \", str(review))\n",
        "        review = re.sub(r\"\\d\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+[a-z]\\s+\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+[a-z]$\", \" \", str(review))\n",
        "        review = re.sub(r\"^[a-z]\\s+\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+\", \" \", str(review))\n",
        "        return review\n",
        "\n",
        "    def remove_punc(self, text):\n",
        "        table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "        return text.translate(table)\n",
        "\n",
        "    def remove_emoticon(self, text):\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "        return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "    \n",
        "    def lemmatization(self, text):\n",
        "        doc = nlp(text)\n",
        "        return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "    nltk.download('stopwords')\n",
        "    def remove_stops(self, text):\n",
        "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "        text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
        "        return \" \".join(text)\n",
        "\n",
        "\n",
        "    def readData1(self, path, inputColumnIndex=0, outputColumnIndex=1):\n",
        "        df = pd.read_csv(path, error_bad_lines=False, sep='\\t')\n",
        "        X = df.iloc[:, inputColumnIndex].values\n",
        "        y = df.iloc[:, outputColumnIndex].values\n",
        "        return X,y\n",
        "    \n",
        "    def readData2(self, path, inputColumnIndex=1, outputColumnIndex=2):\n",
        "        df = pd.read_csv(path, error_bad_lines=False, sep='\\t')\n",
        "        X = df.iloc[:, inputColumnIndex].values\n",
        "        y = df.iloc[:, outputColumnIndex].values\n",
        "        return X,y\n",
        "    \n",
        "    def draw_prediction_results(self, y_pred, y_test, my_tags, method):\n",
        "        print('accuracy of ' + method + ': %s' % accuracy_score(y_pred, y_test))\n",
        "        print(classification_report(y_test, y_pred, target_names=my_tags, digits = 6))\n",
        "\n",
        "    \n",
        "    def crossValidation(self, prediction, input, output, k=5):\n",
        "        scores = cross_val_score(prediction, input,output, cv=k)\n",
        "        print(\"Accuracy of Cross Validation Mean: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "727sZupe6Gxg",
        "outputId": "172eb2bb-11a8-4f5a-ced6-a7aaa9af528f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['vani bhojam fan hit like solli like vangida vendiyathu', 'love ajith like', 'ennaya trailer ku mudi ellam nikkudhu vera level trailer', 'vijay annaa ur maassssss therrrrriiiiii', 'நம ப நட ந ச ம த ன ப ச ச', 'gommala end vera level da deii getrajinifie', 'vjs anna kaaga like potavanga like pannuga', 'theri semma theri joseph kuruvilla vijay kumar awesome kumar', 'ithu yethu maathiri illama puthu maathiyaala irukku', 'wow back baasha mode thalaivaaaa petta paraakkkkk']\n"
          ]
        }
      ],
      "source": [
        "# FUNCTION CALL FOR DATA CLEANING AND PREPARATION #\n",
        "utils = Utils()\n",
        "filepath = \"./traindata1.1.csv\"\n",
        "X1,y_train=utils.readData1(filepath)\n",
        "\n",
        "ourTags =['not-Tamil', 'unknown_state', 'Positive', 'Mixed_feelings', 'Negative']\n",
        "X_train=[]\n",
        "\n",
        "for i in range(0, len(X1)):\n",
        "    t = utils.cleanText(X1[i])\n",
        "    t = utils.remove_emoticon(t)\n",
        "    t = utils.remove_punc(t)\n",
        "    t = utils.remove_stops(t)\n",
        "    t = utils.lemmatization(t)\n",
        "    X_train.append(t)\n",
        "\n",
        "print(X_train[:10])\n",
        "#X_train, X_test, y_train, y_test = train_test_split(corpus, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPsszKRGni1Z"
      },
      "outputs": [],
      "source": [
        "# FUNCTION CALL FOR DATA CLEANING AND PREPARATION #\n",
        "utils = Utils()\n",
        "X2,y_test=utils.readData2('tamil_sentiment_full_test_withtlabels.tsv')\n",
        "\n",
        "X_test=[]\n",
        "\n",
        "for i in range(0, len(X2)):\n",
        "    t = utils.cleanText(X2[i])\n",
        "    t = utils.remove_emoticon(t)\n",
        "    t = utils.remove_punc(t)\n",
        "    t = utils.remove_stops(t)\n",
        "    t = utils.lemmatization(t)\n",
        "    X_test.append(t)\n",
        "#print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqPVciOg-K5c"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODSXTCHsLd8Q",
        "outputId": "38e1bb2e-8493-40fd-91a5-86f5261959dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Logistic Regression: 0.6442526124488869\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.358108  0.112766  0.171521       470\n",
            " unknown_state   0.477663  0.291405  0.361979       477\n",
            "      Positive   0.683634  0.907306  0.779747      2546\n",
            "Mixed_feelings   0.757812  0.397541  0.521505       244\n",
            "      Negative   0.519737  0.356391  0.422837       665\n",
            "\n",
            "      accuracy                       0.644253      4402\n",
            "     macro avg   0.559391  0.413082  0.451518      4402\n",
            "  weighted avg   0.605911  0.644253  0.601306      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LOGISTIC REGRESSION #\n",
        "lrp = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2,analyzer='word', ngram_range=(1, 3))),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('lr', LogisticRegression(max_iter=1000))\n",
        "                ])\n",
        "lrp.fit(X_train, y_train)\n",
        "y_pred = lrp.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred,y_test,ourTags,\"Logistic Regression\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGB5YURAThfx",
        "outputId": "61be1a8e-a6ea-4b8a-90a5-006f3ddf4650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Multinomial Naive Bayes: 0.6256247160381645\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.437500  0.029787  0.055777       470\n",
            " unknown_state   0.500000  0.132075  0.208955       477\n",
            "      Positive   0.627706  0.968185  0.761625      2546\n",
            "Mixed_feelings   0.839286  0.385246  0.528090       244\n",
            "      Negative   0.575610  0.177444  0.271264       665\n",
            "\n",
            "      accuracy                       0.625625      4402\n",
            "     macro avg   0.596020  0.338548  0.365142      4402\n",
            "  weighted avg   0.597417  0.625625  0.539352      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MULTINOMIAL NAIVE BAYES #\n",
        "multinomial_naive_bayes = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('multinomial_naive_bayes',\n",
        "                         MultinomialNB())\n",
        "                        ])\n",
        "multinomial_naive_bayes.fit(X_train, y_train)\n",
        "pred_multinomial_naive_bayes = multinomial_naive_bayes.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_multinomial_naive_bayes,y_test,ourTags,\"Multinomial Naive Bayes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22IIDKIOwTaK",
        "outputId": "ac6cf9a2-e8d6-4410-e5ff-a51255c2609f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Linear SVM: 0.6367560199909132\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.389706  0.112766  0.174917       470\n",
            " unknown_state   0.460317  0.303983  0.366162       477\n",
            "      Positive   0.678603  0.893166  0.771240      2546\n",
            "Mixed_feelings   0.743243  0.450820  0.561224       244\n",
            "      Negative   0.488938  0.332331  0.395703       665\n",
            "\n",
            "      accuracy                       0.636756      4402\n",
            "     macro avg   0.552162  0.418613  0.453849      4402\n",
            "  weighted avg   0.599035  0.636756  0.595304      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LINEAR SVM #\n",
        "linear_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('linear_svc',\n",
        "                        SVC(kernel='linear'))\n",
        "                        ])\n",
        "linear_svm.fit(X_train, y_train)\n",
        "y_pred_svc = linear_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"Linear SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1cYONgUxcBy",
        "outputId": "b5a94d94-a3a9-40d2-bc68-cd67ee43a042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of RBF SVM: 0.6369831894593366\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.500000  0.061702  0.109848       470\n",
            " unknown_state   0.481651  0.220126  0.302158       477\n",
            "      Positive   0.650315  0.932050  0.766102      2546\n",
            "Mixed_feelings   0.746667  0.459016  0.568528       244\n",
            "      Negative   0.565749  0.278195  0.372984       665\n",
            "\n",
            "      accuracy                       0.636983      4402\n",
            "     macro avg   0.588876  0.390218  0.423924      4402\n",
            "  weighted avg   0.608555  0.636983  0.575422      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# RBF SVM #\n",
        "rbf_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('rbf_svc',\n",
        "                        SVC(kernel='rbf', gamma=1))\n",
        "                        ])\n",
        "rbf_svm.fit(X_train, y_train)\n",
        "y_pred_svc = rbf_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"RBF SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-ucCcstztRa",
        "outputId": "627c8538-7853-40bf-ea5f-06f83a052132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of POLY SVM: 0.6365288505224898\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.384058  0.112766  0.174342       470\n",
            " unknown_state   0.460317  0.303983  0.366162       477\n",
            "      Positive   0.678710  0.892773  0.771162      2546\n",
            "Mixed_feelings   0.743243  0.450820  0.561224       244\n",
            "      Negative   0.488938  0.332331  0.395703       665\n",
            "\n",
            "      accuracy                       0.636529      4402\n",
            "     macro avg   0.551053  0.418535  0.453719      4402\n",
            "  weighted avg   0.598494  0.636529  0.595198      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# POLY SVM #\n",
        "poly_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('poly_svc',\n",
        "                        SVC(kernel='poly',degree = 1))\n",
        "                        ])\n",
        "poly_svm.fit(X_train, y_train)\n",
        "y_pred_svc = poly_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"POLY SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ovnOnrv6-Z",
        "outputId": "1fea8bf5-8787-415d-bf9e-1baaeccdc7ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Random Forest: 0.6299409359382099\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.370370  0.042553  0.076336       470\n",
            " unknown_state   0.461864  0.228512  0.305750       477\n",
            "      Positive   0.651751  0.921053  0.763346      2546\n",
            "Mixed_feelings   0.640625  0.504098  0.564220       244\n",
            "      Negative   0.546584  0.264662  0.356636       665\n",
            "\n",
            "      accuracy                       0.629941      4402\n",
            "     macro avg   0.534239  0.392175  0.413258      4402\n",
            "  weighted avg   0.584628  0.629941  0.567931      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# RANDOM FOREST #\n",
        "random_forest = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('random_forest',\n",
        "                         RandomForestClassifier())\n",
        "                        ])\n",
        "random_forest.fit(X_train, y_train)\n",
        "pred_random_forest = random_forest.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_random_forest,y_test,ourTags,\"Random Forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s31N5aEL8rIu",
        "outputId": "837af396-0159-4085-b09d-7168818d34c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of KNeighborsClassifier: 0.5615629259427533\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.114679  0.053191  0.072674       470\n",
            " unknown_state   0.219731  0.102725  0.140000       477\n",
            "      Positive   0.613517  0.873527  0.720791      2546\n",
            "Mixed_feelings   0.400000  0.204918  0.271003       244\n",
            "      Negative   0.587678  0.186466  0.283105       665\n",
            "\n",
            "      accuracy                       0.561563      4402\n",
            "     macro avg   0.387121  0.284166  0.297515      4402\n",
            "  weighted avg   0.501847  0.561563  0.497606      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# KNeighborsClassifier #\n",
        "knn = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('kNN', KNeighborsClassifier(n_neighbors=3))\n",
        "                        ])\n",
        "knn.fit(X_train, y_train)\n",
        "pred_knn = knn.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_knn,y_test,ourTags,\"KNeighborsClassifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc8SBEBsMeo8"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm7FWo_vNqbS",
        "outputId": "d9960914-85dd-4b6c-91ee-ae3621e50bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Extra Tree Classifier: 0.6340299863698319\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.362500  0.061702  0.105455       470\n",
            " unknown_state   0.480620  0.259958  0.337415       477\n",
            "      Positive   0.661455  0.913983  0.767480      2546\n",
            "Mixed_feelings   0.622449  0.500000  0.554545       244\n",
            "      Negative   0.540000  0.284211  0.372414       665\n",
            "\n",
            "      accuracy                       0.634030      4402\n",
            "     macro avg   0.533405  0.403971  0.427462      4402\n",
            "  weighted avg   0.589431  0.634030  0.578710      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# EXTRA TREE CLASSIFIER #\n",
        "extra_tree = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('extra tree',\n",
        "                         ExtraTreesClassifier())\n",
        "                        ])\n",
        "extra_tree.fit(X_train, y_train)\n",
        "pred_extra_tree = extra_tree.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_extra_tree,y_test,ourTags,\"Extra Tree Classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCP0liD9P5Mq",
        "outputId": "50e1facf-d4e1-439c-c4dc-d03173c356b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Hard Ensemble: 0.6381190368014539\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.478873  0.072340  0.125693       470\n",
            " unknown_state   0.504098  0.257862  0.341193       477\n",
            "      Positive   0.651080  0.935192  0.767693      2546\n",
            "Mixed_feelings   0.787879  0.426230  0.553191       244\n",
            "      Negative   0.560403  0.251128  0.346833       665\n",
            "\n",
            "      accuracy                       0.638119      4402\n",
            "     macro avg   0.596467  0.388550  0.426921      4402\n",
            "  weighted avg   0.610651  0.638119  0.577463      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# ALL CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Multinomial Naive Bayes\", multinomial_naive_bayes), (\"Extra Tree\", extra_tree), (\"Random Forest\", random_forest), (\"Poly SVM\", poly_svm), (\"RBF SVM\", rbf_svm), (\"KNeighborsClassifier\", knn)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtugxjUBOlbA",
        "outputId": "0107032b-ba64-4bbf-f3e6-df72577ee10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Hard Ensemble: 0.6426624261699228\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.428571  0.102128  0.164948       470\n",
            " unknown_state   0.487719  0.291405  0.364829       477\n",
            "      Positive   0.671581  0.912412  0.773689      2546\n",
            "Mixed_feelings   0.772059  0.430328  0.552632       244\n",
            "      Negative   0.521951  0.321805  0.398140       665\n",
            "\n",
            "      accuracy                       0.642662      4402\n",
            "     macro avg   0.576376  0.411615  0.450848      4402\n",
            "  weighted avg   0.608677  0.642662  0.595403      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# TOP 5 CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp),  (\"Random Forest\", random_forest), (\"Poly SVM\", poly_svm), (\"RBF SVM\", rbf_svm)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2WVBt7tQ0MA",
        "outputId": "2d0d02c4-37b3-4ecc-b79d-ab4afc11e5ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Hard Ensemble: 0.6367560199909132\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.386861  0.112766  0.174629       470\n",
            " unknown_state   0.460317  0.303983  0.366162       477\n",
            "      Positive   0.678806  0.893166  0.771370      2546\n",
            "Mixed_feelings   0.743243  0.450820  0.561224       244\n",
            "      Negative   0.488938  0.332331  0.395703       665\n",
            "\n",
            "      accuracy                       0.636756      4402\n",
            "     macro avg   0.551633  0.418613  0.453818      4402\n",
            "  weighted avg   0.598849  0.636756  0.595349      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# TOP 3 CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Poly SVM\", poly_svm)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tevtGnJ6RIYh",
        "outputId": "33b9b4b7-c1ee-4ecd-a8fd-1eebe4aa3c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Hard Ensemble: 0.6392548841435711\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.428571  0.102128  0.164948       470\n",
            " unknown_state   0.496454  0.293501  0.368906       477\n",
            "      Positive   0.657755  0.927730  0.769757      2546\n",
            "Mixed_feelings   0.814516  0.413934  0.548913       244\n",
            "      Negative   0.556314  0.245113  0.340292       665\n",
            "\n",
            "      accuracy                       0.639255      4402\n",
            "     macro avg   0.590722  0.396481  0.438563      4402\n",
            "  weighted avg   0.609172  0.639255  0.584626      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# BEST OF ALL CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Multinomial Naive Bayes\", multinomial_naive_bayes), (\"Extra Tree\", extra_tree)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrvYzJMSSl2H",
        "outputId": "778bb9c2-7cda-4c6b-8c8b-4a4c2103e2e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Ada Boost: 0.5860972285324852\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.000000  0.000000  0.000000       470\n",
            " unknown_state   0.000000  0.000000  0.000000       477\n",
            "      Positive   0.608178  0.923016  0.733229      2546\n",
            "Mixed_feelings   0.654206  0.286885  0.398860       244\n",
            "      Negative   0.372093  0.240602  0.292237       665\n",
            "\n",
            "      accuracy                       0.586097      4402\n",
            "     macro avg   0.326895  0.290101  0.284865      4402\n",
            "  weighted avg   0.444227  0.586097  0.490337      4402\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# ADABOOST #\n",
        "#seed = 10\n",
        "num_trees = 25\n",
        "\n",
        "ada_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('ada_boost',\n",
        "                         AdaBoostClassifier(n_estimators=num_trees))\n",
        "                        ])\n",
        "ada_boost.fit(X_train, y_train)\n",
        "pred_ada_boost = ada_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_ada_boost,y_test,ourTags,\"Ada Boost\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVaP26seRJN8",
        "outputId": "9331a703-78c9-4c1e-9e53-1f6765e36798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of XGBoost: 0.6094956837801\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.416667  0.021277  0.040486       470\n",
            " unknown_state   0.559140  0.109015  0.182456       477\n",
            "      Positive   0.607387  0.975255  0.748568      2546\n",
            "Mixed_feelings   0.826087  0.233607  0.364217       244\n",
            "      Negative   0.632812  0.121805  0.204288       665\n",
            "\n",
            "      accuracy                       0.609496      4402\n",
            "     macro avg   0.608419  0.292192  0.308003      4402\n",
            "  weighted avg   0.597759  0.609496  0.508095      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# XGBOOST #\n",
        "xg_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('xgboost',\n",
        "                         XGBClassifier())\n",
        "                        ])\n",
        "xg_boost.fit(X_train, y_train)\n",
        "pred_xg_boost = xg_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_xg_boost,y_test,ourTags,\"XGBoost\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai2QQGdioGlJ",
        "outputId": "05bd8a72-7589-404b-8b30-075f175185bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of XGBoost: 0.6285779191276692\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.324138  0.100000  0.152846       470\n",
            " unknown_state   0.460145  0.266247  0.337317       477\n",
            "      Positive   0.673015  0.902200  0.770935      2546\n",
            "Mixed_feelings   0.658065  0.418033  0.511278       244\n",
            "      Negative   0.469734  0.291729  0.359926       665\n",
            "\n",
            "      accuracy                       0.628578      4402\n",
            "     macro avg   0.517019  0.395642  0.426460      4402\n",
            "  weighted avg   0.581161  0.628578  0.581472      4402\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# XGBOOST #\n",
        "xg_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('xgboost',\n",
        "                         XGBClassifier(learning_rate =0.1,\n",
        " n_estimators=1000,\n",
        " max_depth=5,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " nthread=4,\n",
        " scale_pos_weight=1,\n",
        " seed=27))\n",
        "])\n",
        "xg_boost.fit(X_train, y_train)\n",
        "pred_xg_boost = xg_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_xg_boost,y_test,ourTags,\"XGBoost\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "TamilCMD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "envs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7 (v3.10.7:6cc6b13308, Sep  5 2022, 14:02:52) [Clang 13.0.0 (clang-1300.0.29.30)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "6b16d1a6559efeda66307266d482d01ef10bc024de7015cc43e9f26f0fe94454"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithunkumarsr/CodeMixingDravidianLanguage/blob/main/TamilCMD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wEyEcB2A4dmA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "\n",
        "from sklearn.metrics import accuracy_score,classification_report, f1_score\n",
        "from sklearn.model_selection import cross_val_score, train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5uS6kc4z_8qa"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGgxWSNw42U2",
        "outputId": "8526f855-8ec5-4e3b-a1f2-9ef9e4d11947"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/aapoh/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# DATA CLEANING AND PREPARATION #\n",
        "class Utils(object):\n",
        "\n",
        "    def cleanText(self, text):\n",
        "        review = re.sub(r\"^https://t.co/[a-zA-Z0-9]*\\s\", \" \", str(text))\n",
        "        review = re.sub(r\"\\([\\s\\S]*\\)\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*\\s\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*$\", \" \", str(review))\n",
        "        review = review.lower()\n",
        "        review = re.sub(r\"that's\", \"that is\", str(review))\n",
        "        review = re.sub(r\"there's\", \"there is\", str(review))\n",
        "        review = re.sub(r\"what's\", \"what is\", str(review))\n",
        "        review = re.sub(r\"where's\", \"where is\", str(review))\n",
        "        review = re.sub(r\"it's\", \"it is\", str(review))\n",
        "        review = re.sub(r\"who's\", \"who is\", str(review))\n",
        "        review = re.sub(r\"i'm\", \"i am\", str(review))\n",
        "        review = re.sub(r\"she's\", \"she is\", str(review))\n",
        "        review = re.sub(r\"he's\", \"he is\", str(review))\n",
        "        review = re.sub(r\"they're\", \"they are\", str(review))\n",
        "        review = re.sub(r\"who're\", \"who are\", str(review))\n",
        "        review = re.sub(r\"ain't\", \"am not\", str(review))\n",
        "        review = re.sub(r\"wouldn't\", \"would not\", str(review))\n",
        "        review = re.sub(r\"shouldn't\", \"should not\", str(review))\n",
        "        review = re.sub(r\"can't\", \"can not\", str(review))\n",
        "        review = re.sub(r\"couldn't\", \"could not\", str(review))\n",
        "        review = re.sub(r\"won't\", \"will not\", str(review))\n",
        "        review = re.sub(r\" pm \", \" \", str(review))\n",
        "        review = re.sub(r\" am \", \" \", str(review))\n",
        "        review = re.sub(r'[^\\[\\]]+(?=\\])', \" \", str(review))\n",
        "        review = re.sub(r\"\\W\", \" \", str(review))\n",
        "        review = re.sub(r\"\\d\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+[a-z]\\s+\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+[a-z]$\", \" \", str(review))\n",
        "        review = re.sub(r\"^[a-z]\\s+\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+\", \" \", str(review))\n",
        "        return review\n",
        "\n",
        "    def remove_punc(self, text):\n",
        "        table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "        return text.translate(table)\n",
        "\n",
        "    def remove_emoticon(self, text):\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "        return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "    \n",
        "    def lemmatization(self, text):\n",
        "        doc = nlp(text)\n",
        "        return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "    nltk.download('stopwords')\n",
        "    def remove_stops(self, text):\n",
        "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "        text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
        "        return \" \".join(text)\n",
        "\n",
        "\n",
        "    def readData1(self, path, inputColumnIndex=0, outputColumnIndex=1):\n",
        "        df = pd.read_csv(path, error_bad_lines=False, sep='\\t')\n",
        "        X = df.iloc[:, inputColumnIndex].values\n",
        "        y = df.iloc[:, outputColumnIndex].values\n",
        "        return X,y\n",
        "    \n",
        "    def readData2(self, path, inputColumnIndex=1, outputColumnIndex=2):\n",
        "        df = pd.read_csv(path, error_bad_lines=False, sep='\\t')\n",
        "        X = df.iloc[:, inputColumnIndex].values\n",
        "        y = df.iloc[:, outputColumnIndex].values\n",
        "        return X,y\n",
        "    \n",
        "    def draw_prediction_results(self, y_pred, y_test, my_tags, method):\n",
        "        print('accuracy of ' + method + ': %s' % accuracy_score(y_pred, y_test))\n",
        "        print(classification_report(y_test, y_pred, target_names=my_tags, digits = 6))\n",
        "\n",
        "    \n",
        "    def crossValidation(self, prediction, input, output, k=5):\n",
        "        scores = cross_val_score(prediction, input,output, cv=k)\n",
        "        print(\"Accuracy of Cross Validation Mean: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clean data\n",
        "# from cleantext import clean # helps to remove imoji in text\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# \n",
        "def clean( text ):\n",
        "  '''clean tweet texts and remove links, usernamas'''\n",
        "  text = text.lower()\n",
        "  text = ' '.join( text.split() )\n",
        "  text = ' '.join( [ re.sub(\"^@\\w+\", \" \", t) for t in text.split(' ') ] ) # remove usernames\n",
        "  # text = ' '.join( [ re.sub(\"^@\\w+\", \" \", t) for t in text.split(' ') ] ) # remove hashtags\n",
        "  text = ' '.join( [ re.sub(\"^http\\w+\", \" \", t) for t in text.split(' ') ] ) # remove links\n",
        "  print(text)\n",
        "  text = re.sub(\"[^a-z0-9]\", \" \", text) # remove imoji.\n",
        "  # text = clean(text, no_emoji=True)\n",
        "  return ' '.join( text.split() )\n",
        "\n",
        "# make classes\n",
        "def make_label( class_ ):\n",
        "  ''' \n",
        "  neu   - 0\n",
        "  pos   - 1\n",
        "  neg   - 2\n",
        "  vpos  - 3\n",
        "  vneg  - 4\n",
        "  '''\n",
        "  class_ = class_.lower()\n",
        "  if class_ == 'vneg': return 4\n",
        "  elif class_ == 'neu': return 0\n",
        "  elif class_ == 'neg': return 2\n",
        "  elif class_ == 'vpos': return 3\n",
        "  elif class_ == 'pos': return 1\n",
        "  \n",
        "  \n",
        "# load data\n",
        "data = pd.read_csv(\"./traindata1.1.csv\",engine=\"python\", encoding='utf-8')\n",
        "data.drop(axis=1, inplace=True, columns=['UserID','Date/Time'] )\n",
        "data.drop_duplicates(inplace=True)\n",
        "data['shona_cleaned'] = data['SN(Original Shona Tweet)'].apply( clean ) # clean shona tweets.\n",
        "data['Label5'] = data['finalLabel5Classes'].apply( make_label )\n",
        "df = data[[ 'shona_cleaned', 'Label5']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "727sZupe6Gxg",
        "outputId": "172eb2bb-11a8-4f5a-ced6-a7aaa9af528f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['nhasi mukoma abva amuka hake achiudza vanhu chokwadi', 'hahahaha vaudze vana ava vanomhanya kuitisa nharo pasina kana ruzivo', 'haasi kuforca vanhu hake arikungoti anoda kuterera ngaaterere asingade oita zvelife yake asi asazodzoke kwatiri akuchema achida kucomfortwa isu toseka chete', 'uyu wemasupa uyu', 'zvinoshamisa ndezvokuti zvimwe zvakasara zvakazvikara asi akazoita zvokukushanyirwa simba nazvo akabhira basa rekuita kuti agone kugona kuronga vanhu vakazoronga vakazomurwira co jon ijis', 'ko kna ndine nzara', 'let talk kugadzira mbudzi round bhoo mota dzinobva nekuna highglen road goin kuna beatrice road makazoti vanoenda nekupi zviya can not havin truck usin ghetto single lane vana havachato famba muroad chimhanda zvakurirwa plizz help', 'dai watotengera mwana wako hanzi ndinoda vana vangu', 'huya pano wine glass sorry asi ndiwe wandafunga pandaona tweet tikasakubata uchitaura naro muguva girazi rewine zve winethursday', 'roorai vakadzidza vakadzidza face nemagaro hazviitise mwana homework']\n"
          ]
        }
      ],
      "source": [
        "# FUNCTION CALL FOR DATA CLEANING AND PREPARATION #\n",
        "utils = Utils()\n",
        "# filepath = \"./traindata1.1.csv\"\n",
        "# X1,y_train=utils.readData1(filepath)\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['shona_cleaned'], df['Label5'], test_size=0.3, random_state=42)\n",
        "\n",
        "ourTags =['neutral', 'positive', 'negative', 'very-positive', 'very-negative']\n",
        "X_train=[]\n",
        "\n",
        "for i in range(0, len(x_train.values)):\n",
        "    t = utils.cleanText(x_train.values[i])\n",
        "    t = utils.remove_emoticon(t)\n",
        "    t = utils.remove_punc(t)\n",
        "    t = utils.remove_stops(t)\n",
        "    t = utils.lemmatization(t)\n",
        "    X_train.append(t)\n",
        "\n",
        "print(X_train[ : 10] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kPsszKRGni1Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['chitowamombe cde gwasai lecture yaisapera pasina kutaurwa nezve song ya winky', 'atova nekutonga misa mutongo misa misa ita mutongo na hrs wozoikanda nyaya yako mumabhini nemudhudhusi imboko vanhu vezanu', 'akuhumana uyu', 'kusvika wati eke chinhu chawo wawe kuchida', 'usamhanye mwana weafrica co bfbkflmab', 'aaaaaa mdhara nababa vako ko hausikumbofunga mai vako', 'danai mai vevana ndakuvara kuno co khcmxr', 'sit talk like old nekupihwa note na mdara cz unenge waniwa zvirinani na baba vako random ama mf', 'unodei ita kuti usazvinetse nezvachamisa', 'chembera mushe iwe chisekuru potera zvakanaka makapera panonaka kudhara mbavha iwe']\n"
          ]
        }
      ],
      "source": [
        "# FUNCTION CALL FOR DATA CLEANING AND PREPARATION #\n",
        "# utils = Utils()\n",
        "# X2,y_test=utils.readData2('tamil_sentiment_full_test_withtlabels.tsv')\n",
        "\n",
        "X_test=[]\n",
        "\n",
        "for i in range(0, len(x_test.values)):\n",
        "    t = utils.cleanText(x_test.values[i])\n",
        "    t = utils.remove_emoticon(t)\n",
        "    t = utils.remove_punc(t)\n",
        "    t = utils.remove_stops(t)\n",
        "    t = utils.lemmatization(t)\n",
        "    X_test.append(t)\n",
        "# \n",
        "print(X_test[: 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rqPVciOg-K5c"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODSXTCHsLd8Q",
        "outputId": "38e1bb2e-8493-40fd-91a5-86f5261959dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Logistic Regression: 0.46248946333239677\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.515373  0.451282  0.481203       780\n",
            "     positive   0.433451  0.521246  0.473312       706\n",
            "     negative   0.450000  0.628743  0.524563      1002\n",
            "very-positive   0.673913  0.169399  0.270742       366\n",
            "very-negative   0.437383  0.331915  0.377419       705\n",
            "\n",
            "     accuracy                       0.462489      3559\n",
            "    macro avg   0.502024  0.420517  0.425448      3559\n",
            " weighted avg   0.481572  0.462489  0.449643      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LOGISTIC REGRESSION #\n",
        "lrp = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2,analyzer='word', ngram_range=(1, 3))),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('lr', LogisticRegression(max_iter=1000))\n",
        "                ])\n",
        "lrp.fit(X_train, y_train)\n",
        "y_pred = lrp.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred,y_test,ourTags,\"Logistic Regression\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGB5YURAThfx",
        "outputId": "61be1a8e-a6ea-4b8a-90a5-006f3ddf4650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Multinomial Naive Bayes: 0.43692048328182076\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.602410  0.320513  0.418410       780\n",
            "     positive   0.464088  0.475921  0.469930       706\n",
            "     negative   0.382789  0.772455  0.511905      1002\n",
            "very-positive   0.878788  0.079235  0.145363       366\n",
            "very-negative   0.454795  0.235461  0.310280       705\n",
            "\n",
            "     accuracy                       0.436920      3559\n",
            "    macro avg   0.556574  0.376717  0.371178      3559\n",
            " weighted avg   0.512320  0.436920  0.405454      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MULTINOMIAL NAIVE BAYES #\n",
        "multinomial_naive_bayes = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('multinomial_naive_bayes',\n",
        "                         MultinomialNB())\n",
        "                        ])\n",
        "multinomial_naive_bayes.fit(X_train, y_train)\n",
        "pred_multinomial_naive_bayes = multinomial_naive_bayes.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_multinomial_naive_bayes,y_test,ourTags,\"Multinomial Naive Bayes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22IIDKIOwTaK",
        "outputId": "ac6cf9a2-e8d6-4410-e5ff-a51255c2609f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Linear SVM: 0.4661421747681933\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.490119  0.476923  0.483431       780\n",
            "     positive   0.431235  0.524079  0.473146       706\n",
            "     negative   0.473684  0.592814  0.526596      1002\n",
            "very-positive   0.644628  0.213115  0.320329       366\n",
            "very-negative   0.432099  0.347518  0.385220       705\n",
            "\n",
            "     accuracy                       0.466142      3559\n",
            "    macro avg   0.494353  0.430890  0.437744      3559\n",
            " weighted avg   0.478207  0.466142  0.457316      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LINEAR SVM #\n",
        "linear_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('linear_svc',\n",
        "                        SVC(kernel='linear'))\n",
        "                        ])\n",
        "linear_svm.fit(X_train, y_train)\n",
        "y_pred_svc = linear_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"Linear SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1cYONgUxcBy",
        "outputId": "b5a94d94-a3a9-40d2-bc68-cd67ee43a042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of RBF SVM: 0.531610002809778\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.656146  0.506410  0.571635       780\n",
            "     positive   0.491061  0.583569  0.533333       706\n",
            "     negative   0.477483  0.719561  0.574045      1002\n",
            "very-positive   0.853448  0.270492  0.410788       366\n",
            "very-negative   0.538618  0.375887  0.442774       705\n",
            "\n",
            "     accuracy                       0.531610      3559\n",
            "    macro avg   0.603351  0.491184  0.506515      3559\n",
            " weighted avg   0.570106  0.531610  0.522648      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# RBF SVM #\n",
        "rbf_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('rbf_svc',\n",
        "                        SVC(kernel='rbf', gamma=1))\n",
        "                        ])\n",
        "rbf_svm.fit(X_train, y_train)\n",
        "y_pred_svc = rbf_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"RBF SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-ucCcstztRa",
        "outputId": "627c8538-7853-40bf-ea5f-06f83a052132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of POLY SVM: 0.4664231525709469\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.488830  0.476923  0.482803       780\n",
            "     positive   0.433763  0.524079  0.474663       706\n",
            "     negative   0.472510  0.591816  0.525476      1002\n",
            "very-positive   0.644628  0.213115  0.320329       366\n",
            "very-negative   0.434095  0.350355  0.387755       705\n",
            "\n",
            "     accuracy                       0.466423      3559\n",
            "    macro avg   0.494765  0.431258  0.438205      3559\n",
            " weighted avg   0.478491  0.466423  0.457666      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# POLY SVM #\n",
        "poly_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('poly_svc',\n",
        "                        SVC(kernel='poly',degree = 1))\n",
        "                        ])\n",
        "poly_svm.fit(X_train, y_train)\n",
        "y_pred_svc = poly_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"POLY SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ovnOnrv6-Z",
        "outputId": "1fea8bf5-8787-415d-bf9e-1baaeccdc7ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Random Forest: 0.5375105366676033\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.640502  0.523077  0.575865       780\n",
            "     positive   0.508855  0.610482  0.555055       706\n",
            "     negative   0.489240  0.680639  0.569282      1002\n",
            "very-positive   0.711111  0.349727  0.468864       366\n",
            "very-negative   0.526946  0.374468  0.437811       705\n",
            "\n",
            "     accuracy                       0.537511      3559\n",
            "    macro avg   0.575331  0.507678  0.521375      3559\n",
            " weighted avg   0.556568  0.537511  0.531533      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# RANDOM FOREST #\n",
        "random_forest = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('random_forest',\n",
        "                         RandomForestClassifier())\n",
        "                        ])\n",
        "random_forest.fit(X_train, y_train)\n",
        "pred_random_forest = random_forest.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_random_forest,y_test,ourTags,\"Random Forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s31N5aEL8rIu",
        "outputId": "837af396-0159-4085-b09d-7168818d34c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of KNeighborsClassifier: 0.41753301489182354\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.583333  0.511538  0.545082       780\n",
            "     positive   0.281159  0.824363  0.419308       706\n",
            "     negative   0.657944  0.351297  0.458035      1002\n",
            "very-positive   0.580000  0.079235  0.139423       366\n",
            "very-negative   0.563636  0.175887  0.268108       705\n",
            "\n",
            "     accuracy                       0.417533      3559\n",
            "    macro avg   0.533215  0.388464  0.365991      3559\n",
            " weighted avg   0.540152  0.417533  0.399042      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# KNeighborsClassifier #\n",
        "knn = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('kNN', KNeighborsClassifier(n_neighbors=3))\n",
        "                        ])\n",
        "knn.fit(X_train, y_train)\n",
        "pred_knn = knn.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_knn,y_test,ourTags,\"KNeighborsClassifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Jc8SBEBsMeo8"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm7FWo_vNqbS",
        "outputId": "d9960914-85dd-4b6c-91ee-ae3621e50bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Extra Tree Classifier: 0.541725203708907\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.641902  0.553846  0.594632       780\n",
            "     positive   0.482163  0.593484  0.532063       706\n",
            "     negative   0.522709  0.654691  0.581303      1002\n",
            "very-positive   0.648780  0.363388  0.465849       366\n",
            "very-negative   0.517056  0.408511  0.456418       705\n",
            "\n",
            "     accuracy                       0.541725      3559\n",
            "    macro avg   0.562522  0.514784  0.526053      3559\n",
            " weighted avg   0.552634  0.541725  0.537845      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# EXTRA TREE CLASSIFIER #\n",
        "extra_tree = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('extra tree',\n",
        "                         ExtraTreesClassifier())\n",
        "                        ])\n",
        "extra_tree.fit(X_train, y_train)\n",
        "pred_extra_tree = extra_tree.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_extra_tree,y_test,ourTags,\"Extra Tree Classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCP0liD9P5Mq",
        "outputId": "50e1facf-d4e1-439c-c4dc-d03173c356b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Hard Ensemble: 0.5071649339702163\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.575172  0.534615  0.554153       780\n",
            "     positive   0.461794  0.590652  0.518334       706\n",
            "     negative   0.484982  0.660679  0.559358      1002\n",
            "very-positive   0.791667  0.207650  0.329004       366\n",
            "very-negative   0.495745  0.330496  0.396596       705\n",
            "\n",
            "     accuracy                       0.507165      3559\n",
            "    macro avg   0.561872  0.464818  0.471489      3559\n",
            " weighted avg   0.533819  0.507165  0.494149      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# ALL CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Multinomial Naive Bayes\", multinomial_naive_bayes), (\"Extra Tree\", extra_tree), (\"Random Forest\", random_forest), (\"Poly SVM\", poly_svm), (\"RBF SVM\", rbf_svm), (\"KNeighborsClassifier\", knn)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtugxjUBOlbA",
        "outputId": "0107032b-ba64-4bbf-f3e6-df72577ee10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Hard Ensemble: 0.47822422028659733\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.520604  0.485897  0.502653       780\n",
            "     positive   0.438679  0.526912  0.478764       706\n",
            "     negative   0.467706  0.628743  0.536398      1002\n",
            "very-positive   0.728972  0.213115  0.329810       366\n",
            "very-negative   0.459357  0.344681  0.393841       705\n",
            "\n",
            "     accuracy                       0.478224      3559\n",
            "    macro avg   0.523064  0.439870  0.448293      3559\n",
            " weighted avg   0.498756  0.478224  0.468086      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# TOP 5 CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp),  (\"Random Forest\", random_forest), (\"Poly SVM\", poly_svm), (\"RBF SVM\", rbf_svm)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2WVBt7tQ0MA",
        "outputId": "2d0d02c4-37b3-4ecc-b79d-ab4afc11e5ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Hard Ensemble: 0.4664231525709469\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.490145  0.478205  0.484101       780\n",
            "     positive   0.433255  0.524079  0.474359       706\n",
            "     negative   0.472554  0.592814  0.525896      1002\n",
            "very-positive   0.644628  0.213115  0.320329       366\n",
            "very-negative   0.432862  0.347518  0.385523       705\n",
            "\n",
            "     accuracy                       0.466423      3559\n",
            "    macro avg   0.494689  0.431146  0.438042      3559\n",
            " weighted avg   0.478447  0.466423  0.457566      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# TOP 3 CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Poly SVM\", poly_svm)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tevtGnJ6RIYh",
        "outputId": "33b9b4b7-c1ee-4ecd-a8fd-1eebe4aa3c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Hard Ensemble: 0.4779432424838438\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.526093  0.478205  0.501007       780\n",
            "     positive   0.438717  0.542493  0.485117       706\n",
            "     negative   0.462396  0.662675  0.544709      1002\n",
            "very-positive   0.758621  0.180328  0.291391       366\n",
            "very-negative   0.473568  0.304965  0.371009       705\n",
            "\n",
            "     accuracy                       0.477943      3559\n",
            "    macro avg   0.531879  0.433733  0.438647      3559\n",
            " weighted avg   0.504335  0.477943  0.462851      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# BEST OF ALL CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Multinomial Naive Bayes\", multinomial_naive_bayes), (\"Extra Tree\", extra_tree)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrvYzJMSSl2H",
        "outputId": "778bb9c2-7cda-4c6b-8c8b-4a4c2103e2e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of Ada Boost: 0.340545096937342\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.409357  0.089744  0.147213       780\n",
            "     positive   0.330460  0.488669  0.394286       706\n",
            "     negative   0.335350  0.663673  0.445561      1002\n",
            "very-positive   0.467890  0.139344  0.214737       366\n",
            "very-negative   0.321429  0.114894  0.169279       705\n",
            "\n",
            "     accuracy                       0.340545      3559\n",
            "    macro avg   0.372897  0.299265  0.274215      3559\n",
            " weighted avg   0.361472  0.340545  0.291537      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ADABOOST #\n",
        "#seed = 10\n",
        "num_trees = 25\n",
        "\n",
        "ada_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('ada_boost',\n",
        "                         AdaBoostClassifier(n_estimators=num_trees))\n",
        "                        ])\n",
        "ada_boost.fit(X_train, y_train)\n",
        "pred_ada_boost = ada_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_ada_boost,y_test,ourTags,\"Ada Boost\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVaP26seRJN8",
        "outputId": "9331a703-78c9-4c1e-9e53-1f6765e36798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of XGBoost: 0.4523742624332678\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.540187  0.370513  0.439544       780\n",
            "     positive   0.447433  0.518414  0.480315       706\n",
            "     negative   0.414649  0.666667  0.511290      1002\n",
            "very-positive   0.518987  0.224044  0.312977       366\n",
            "very-negative   0.469108  0.290780  0.359019       705\n",
            "\n",
            "     accuracy                       0.452374      3559\n",
            "    macro avg   0.478073  0.414083  0.420629      3559\n",
            " weighted avg   0.470183  0.452374  0.438864      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# XGBOOST #\n",
        "xg_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('xgboost',\n",
        "                         XGBClassifier())\n",
        "                        ])\n",
        "xg_boost.fit(X_train, y_train)\n",
        "pred_xg_boost = xg_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_xg_boost,y_test,ourTags,\"XGBoost\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai2QQGdioGlJ",
        "outputId": "05bd8a72-7589-404b-8b30-075f175185bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20:58:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/learner.cc:767: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "accuracy of XGBoost: 0.48215790952514753\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral   0.531915  0.480769  0.505051       780\n",
            "     positive   0.467662  0.532578  0.498013       706\n",
            "     negative   0.466027  0.581836  0.517532      1002\n",
            "very-positive   0.502183  0.314208  0.386555       366\n",
            "very-negative   0.468421  0.378723  0.418824       705\n",
            "\n",
            "     accuracy                       0.482158      3559\n",
            "    macro avg   0.487242  0.457623  0.465195      3559\n",
            " weighted avg   0.484984  0.482158  0.477902      3559\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# XGBOOST #\n",
        "xg_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('xgboost',\n",
        "                         XGBClassifier(learning_rate =0.1,\n",
        " n_estimators=1000,\n",
        " max_depth=5,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " nthread=4,\n",
        " scale_pos_weight=1,\n",
        " seed=27))\n",
        "])\n",
        "xg_boost.fit(X_train, y_train)\n",
        "pred_xg_boost = xg_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_xg_boost,y_test,ourTags,\"XGBoost\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "TamilCMD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "envs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "6b16d1a6559efeda66307266d482d01ef10bc024de7015cc43e9f26f0fe94454"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

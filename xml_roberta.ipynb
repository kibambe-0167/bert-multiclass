{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R6hjla7U36Cp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-1.13.1-cp310-none-macosx_11_0_arm64.whl (53.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.2/53.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in ./envs/lib/python3.10/site-packages (from torch) (4.4.0)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.13.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aapoh/codes/ghp/bert-multiclass/envs/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# install torch \n",
        "# !pip install \"torch == 1.10.2\"# load base package for the tasks from pytorchimport torch\n",
        "!pip install torch\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4v-bax09Kro4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ],
      "source": [
        "# tell pytorch to run this model on GPU\n",
        "# model.cuda()\n",
        "import torch # check if we have cuda installed\n",
        "if torch.cuda.is_available():    # to use GPU\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('GPU is:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2UZ79O-1K5s",
        "outputId": "ccce5e3e-c856-4726-e4f9-52cea1a026b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nyFdIXdo1mWb",
        "outputId": "f4f399ad-e824-4519-dbf7-6ba71a6492a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SN(Original Shona Tweet)</th>\n",
              "      <th>finalLabel5Classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@GombaGuru @__vigie üòÇüòÇ ah mudhara inzwaiwo tsi...</td>\n",
              "      <td>VNEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@ChinyandeGeorge @ngadziore @nancynjenge @tapc...</td>\n",
              "      <td>NEU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Munenge muchiseka vanhu vari single imi muchii...</td>\n",
              "      <td>NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Sharonrose918 @habeeb_zw uyu oita sei</td>\n",
              "      <td>NEU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@baba_nyenyedzi Am honest and practical questi...</td>\n",
              "      <td>VPOS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            SN(Original Shona Tweet) finalLabel5Classes\n",
              "0  @GombaGuru @__vigie üòÇüòÇ ah mudhara inzwaiwo tsi...               VNEG\n",
              "1  @ChinyandeGeorge @ngadziore @nancynjenge @tapc...                NEU\n",
              "2  Munenge muchiseka vanhu vari single imi muchii...                NEG\n",
              "3             @Sharonrose918 @habeeb_zw uyu oita sei                NEU\n",
              "4  @baba_nyenyedzi Am honest and practical questi...               VPOS"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"./traindata1.1.csv\",engine=\"python\")\n",
        "df.drop(axis=1, inplace=True, columns=['UserID','Date/Time'] )\n",
        "df.drop_duplicates(inplace=True)\n",
        "# feature column and target\n",
        "# SN(Original Shona Tweet) | finalLabel5Classes\n",
        "df[['SN(Original Shona Tweet)','finalLabel5Classes']].head(5)\n",
        "# df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "K5JPjdnc3Lum",
        "outputId": "c1c29ee9-e809-481a-d1bb-6eae5300c578"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>SearchTerm</th>\n",
              "      <th>emoticonBased</th>\n",
              "      <th>lexiconBased</th>\n",
              "      <th>Annotation 1</th>\n",
              "      <th>Annotation 2</th>\n",
              "      <th>Annotation 3</th>\n",
              "      <th>finalLabel5Classes</th>\n",
              "      <th>finalLabel3Classes</th>\n",
              "      <th>SN(Original Shona Tweet)</th>\n",
              "      <th>ENGoogleTranslate</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Education</td>\n",
              "      <td>Vana</td>\n",
              "      <td>POS</td>\n",
              "      <td>NEG</td>\n",
              "      <td>VNEG</td>\n",
              "      <td>VNEG</td>\n",
              "      <td>NEU</td>\n",
              "      <td>VNEG</td>\n",
              "      <td>NEG</td>\n",
              "      <td>@GombaGuru @__vigie üòÇüòÇ ah mudhara inzwaiwo tsi...</td>\n",
              "      <td>'g oh mammal feel sorry for the kids wod out w...</td>\n",
              "      <td>gombaguru vigie ah mudhara inzwaiwo tsitsi van...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Agriculture</td>\n",
              "      <td>kudya</td>\n",
              "      <td>UNK</td>\n",
              "      <td>UNK</td>\n",
              "      <td>NEU</td>\n",
              "      <td>NEU</td>\n",
              "      <td>VPOS</td>\n",
              "      <td>NEU</td>\n",
              "      <td>NEU</td>\n",
              "      <td>@ChinyandeGeorge @ngadziore @nancynjenge @tapc...</td>\n",
              "      <td>'my message is a response to your demand that ...</td>\n",
              "      <td>chinyandegeorge ngadziore nancynjenge boriscde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sanitation</td>\n",
              "      <td>Vanhu</td>\n",
              "      <td>UNK</td>\n",
              "      <td>POS</td>\n",
              "      <td>NEG</td>\n",
              "      <td>NEU</td>\n",
              "      <td>NEG</td>\n",
              "      <td>NEG</td>\n",
              "      <td>NEG</td>\n",
              "      <td>Munenge muchiseka vanhu vari single imi muchii...</td>\n",
              "      <td>'you are making fun of people who are single y...</td>\n",
              "      <td>munenge muchiseka vanhu vari single imi muchii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Finance</td>\n",
              "      <td>uyu</td>\n",
              "      <td>UNK</td>\n",
              "      <td>UNK</td>\n",
              "      <td>NEU</td>\n",
              "      <td>NEU</td>\n",
              "      <td>VNEG</td>\n",
              "      <td>NEU</td>\n",
              "      <td>NEU</td>\n",
              "      <td>@Sharonrose918 @habeeb_zw uyu oita sei</td>\n",
              "      <td>'g is how to do'</td>\n",
              "      <td>habeebzw uyu oita sei</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Home_Affairs</td>\n",
              "      <td>Baba</td>\n",
              "      <td>POS</td>\n",
              "      <td>POS</td>\n",
              "      <td>NEU</td>\n",
              "      <td>VPOS</td>\n",
              "      <td>VPOS</td>\n",
              "      <td>VPOS</td>\n",
              "      <td>POS</td>\n",
              "      <td>@baba_nyenyedzi Am honest and practical questi...</td>\n",
              "      <td>'g am honest and prectical quetical quems perm...</td>\n",
              "      <td>babanyenyedzi am honest and practical question...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          topic SearchTerm emoticonBased lexiconBased Annotation 1  \\\n",
              "0     Education       Vana           POS          NEG         VNEG   \n",
              "1   Agriculture      kudya           UNK          UNK          NEU   \n",
              "2   Sanitation       Vanhu           UNK          POS          NEG   \n",
              "3       Finance        uyu           UNK          UNK          NEU   \n",
              "4  Home_Affairs       Baba           POS          POS          NEU   \n",
              "\n",
              "  Annotation 2 Annotation 3 finalLabel5Classes finalLabel3Classes  \\\n",
              "0         VNEG          NEU               VNEG                NEG   \n",
              "1          NEU         VPOS                NEU                NEU   \n",
              "2          NEU          NEG                NEG                NEG   \n",
              "3          NEU         VNEG                NEU                NEU   \n",
              "4         VPOS         VPOS               VPOS                POS   \n",
              "\n",
              "                            SN(Original Shona Tweet)  \\\n",
              "0  @GombaGuru @__vigie üòÇüòÇ ah mudhara inzwaiwo tsi...   \n",
              "1  @ChinyandeGeorge @ngadziore @nancynjenge @tapc...   \n",
              "2  Munenge muchiseka vanhu vari single imi muchii...   \n",
              "3             @Sharonrose918 @habeeb_zw uyu oita sei   \n",
              "4  @baba_nyenyedzi Am honest and practical questi...   \n",
              "\n",
              "                                   ENGoogleTranslate  \\\n",
              "0  'g oh mammal feel sorry for the kids wod out w...   \n",
              "1  'my message is a response to your demand that ...   \n",
              "2  'you are making fun of people who are single y...   \n",
              "3                                   'g is how to do'   \n",
              "4  'g am honest and prectical quetical quems perm...   \n",
              "\n",
              "                                                Text  \n",
              "0  gombaguru vigie ah mudhara inzwaiwo tsitsi van...  \n",
              "1  chinyandegeorge ngadziore nancynjenge boriscde...  \n",
              "2  munenge muchiseka vanhu vari single imi muchii...  \n",
              "3                              habeebzw uyu oita sei  \n",
              "4  babanyenyedzi am honest and practical question...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # text processing function \n",
        "\n",
        "import re\n",
        "import string\n",
        "def clean_text(text):\n",
        "    # to lower case\n",
        "    text = text.lower()\n",
        "    # remove links\n",
        "    text = re.sub('https:\\/\\/\\S+', '', text) \n",
        "    # remove punctuation\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) \n",
        "    # remove next line     \n",
        "    text = re.sub(r'[^ \\w\\.]', '', text) \n",
        "    # remove words containing numbers\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "\n",
        "    text = ' '.join( text.split() )\n",
        "    \n",
        "    return text# Create a new column called \"Text\" for collecting clean text\n",
        "df['Text'] = df['SN(Original Shona Tweet)'].apply(lambda x: clean_text(x))\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmLc6cVr03u3",
        "outputId": "4430da35-b554-4123-90bb-da8e79bda503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in ./envs/lib/python3.10/site-packages (4.26.0.dev0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./envs/lib/python3.10/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in ./envs/lib/python3.10/site-packages (from transformers) (22.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./envs/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./envs/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in ./envs/lib/python3.10/site-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: requests in ./envs/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: filelock in ./envs/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./envs/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in ./envs/lib/python3.10/site-packages (from transformers) (1.24.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./envs/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./envs/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./envs/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./envs/lib/python3.10/site-packages (from requests->transformers) (1.26.13)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in ./envs/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "# install transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXDt_JhD4J8X",
        "outputId": "418096a2-8223-423f-d531-3ffc07123ea8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 615/615 [00:00<00:00, 247kB/s]\n",
            "Downloading:   8%|‚ñä         | 426k/5.07M [00:01<00:12, 376kB/s]  "
          ]
        }
      ],
      "source": [
        "# load xml roberta tokens\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')# Add words into token \n",
        "tokenizer.add_tokens(['covid', 'coronavirus'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwGX9XOd4bgB",
        "outputId": "5c01cfb7-b577-4fc0-83e3-0ac3b39c152a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'gombaguru': [79355, 11, 35451], 'vigie': [279, 16857], 'ah': [1263], 'mudhara': [842, 119989], 'inzwaiwo': [23, 12781, 14, 3613], 'tsitsi': [74185, 19156], 'vana': [131, 11], 'vatambura': [307, 2537, 119145], 'kunze': [949, 731], 'uku': [7316]}\n"
          ]
        }
      ],
      "source": [
        "# example of tokenizing a sentence.\n",
        "df.Text.values[0]\n",
        "print({x : tokenizer.encode(x, add_special_tokens=False) for x in df.Text.values[0].split()})\n",
        "# tokenizer(df.Text.values[0])['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "bORZPp5f5TJY",
        "outputId": "28249a5e-c7d7-4591-e80a-35857a69cfa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max:  147\n",
            "min:  3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([   0.,  500., 1000., 1500., 2000., 2500., 3000., 3500., 4000.,\n",
              "        4500.]), <a list of 10 Text major ticklabel objects>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# tokenize all sentences and see length of the distribution length of the tokenized sentences.\n",
        "# install matplotlib\n",
        "# !pip install matplotlib # tokenize the text feature \n",
        "tokenized_feature_raw = tokenizer.batch_encode_plus(\n",
        "                            # Sentences to encode\n",
        "                            df.Text.values.tolist(), \n",
        "                            # Add '[CLS]' and '[SEP]'\n",
        "                            add_special_tokens = True      \n",
        "                   )# collect tokenized sentence length \n",
        "token_sentence_length = [len(x) for x in tokenized_feature_raw['input_ids']]\n",
        "print('max: ', max(token_sentence_length))\n",
        "print('min: ', min(token_sentence_length))# plot the distribution\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.hist(token_sentence_length, rwidth = 0.9)\n",
        "plt.xlabel('Sequence Length', fontsize = 18)\n",
        "plt.ylabel('# of Samples', fontsize = 18)\n",
        "plt.xticks(fontsize = 14)\n",
        "plt.yticks(fontsize = 14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GG7UN12x6Drh"
      },
      "outputs": [],
      "source": [
        "# identify features and target\n",
        "features = df.Text.values.tolist()\n",
        "target = df['finalLabel5Classes'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cNPtm6ci6PpN"
      },
      "outputs": [],
      "source": [
        "# tokenize features \n",
        "MAX_LEN = 256\n",
        "tokenized_feature = tokenizer.batch_encode_plus(\n",
        "                            # Sentences to encode\n",
        "                            features, \n",
        "                            # Add '[CLS]' and '[SEP]'\n",
        "                            add_special_tokens = True,\n",
        "                            # Add empty tokens if len(text)<MAX_LEN\n",
        "                            padding = 'max_length',\n",
        "                            # Truncate all sentences to max length\n",
        "                            truncation=True,\n",
        "                            # Set the maximum length\n",
        "                            max_length = MAX_LEN, \n",
        "                            # Return attention mask\n",
        "                            return_attention_mask = True,\n",
        "                            # Return pytorch tensors\n",
        "                            return_tensors = 'pt'       \n",
        "                   )\n",
        "# tokenized_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVoyHE6n64nU",
        "outputId": "e6248d9c-4668-4d80-aa5a-c1a0c84f4f5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 1, 0, ..., 0, 1, 0])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# encode the target to numeric using sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit(target)\n",
        "target_num = le.transform(target)\n",
        "target_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ejf66TcI7mOz"
      },
      "outputs": [],
      "source": [
        "# Use 80% for training and 20% for validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(\n",
        "    tokenized_feature['input_ids'], target_num, tokenized_feature['attention_mask'],\n",
        "    random_state=2018, test_size=0.2, stratify=target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5Y15FwOY8Ep6"
      },
      "outputs": [],
      "source": [
        "# load training and validation data, into torch dataloader\n",
        "# define batch_size\n",
        "batch_size = 16 # Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)# Create the DataLoader for our test set\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, torch.tensor(validation_labels))\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbCbfBuE8unM",
        "outputId": "d46437f4-0bf1-461f-9c8a-428a44e7722e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# BertForSequenceClassification\n",
        "from transformers import XLMRobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    \"xlm-roberta-base\", \n",
        "    # Specify number of classes\n",
        "    num_labels = len(set(target)), \n",
        "    # Whether the model returns attentions weights\n",
        "    output_attentions = False,\n",
        "    # Whether the model returns all hidden-states \n",
        "    output_hidden_states = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atPuQGWJ9RNe",
        "outputId": "c04ceab0-a46f-490a-d4dd-8cb21074f23c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(250004, 768)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Because we add two words [‚Äòcovid‚Äô, ‚Äòcoronavirus‚Äô] into the vocabulary, \n",
        "# we will need to resize the token to make sure the model pick it up as whole words.\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp_yfmhI9gPJ",
        "outputId": "a4167560-fba1-4ba9-e138-7304b4b2f5ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# add the optimizer\n",
        "# Optimizer & Learning Rate Scheduler\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_8M-BWWy9quP"
      },
      "outputs": [],
      "source": [
        "# Number of training epochs\n",
        "epochs = 4# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs# Create the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT1lU3uN95jc",
        "outputId": "27714c2e-5afd-487d-a326-bb3f60cf7a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total steps per epoch:  37.125\n",
            "training on epoch:  0\n",
            "training on step:  50\n",
            "total time used is: 780.82 s\n",
            "training on step:  100\n",
            "total time used is: 1540.12 s\n",
            "training on step:  150\n",
            "total time used is: 2290.61 s\n",
            "training on step:  200\n",
            "total time used is: 3045.68 s\n",
            "training on step:  250\n",
            "total time used is: 3793.91 s\n",
            "training on step:  300\n",
            "total time used is: 4549.96 s\n",
            "training on step:  350\n",
            "total time used is: 5297.46 s\n"
          ]
        }
      ],
      "source": [
        "# training the model.\n",
        "# Training\n",
        "import time# Store the average loss after each epoch \n",
        "loss_values = []# number of total steps for each epoch\n",
        "print('total steps per epoch: ',  len(train_dataloader) / batch_size)# looping over epochs\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    print('training on epoch: ', epoch_i)    # set start time \n",
        "    t0 = time.time()\n",
        "    # reset total loss\n",
        "    total_loss = 0\n",
        "    # model in training \n",
        "    model.train()\n",
        "    # loop through batch \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 50 step \n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('training on step: ', step)\n",
        "            print('total time used is: {0:.2f} s'.format(time.time() - t0))\n",
        "        # load data from dataloader \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # clear any previously calculated gradients \n",
        "        model.zero_grad()\n",
        "        # get outputs\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "        # get loss\n",
        "        loss = outputs[0]\n",
        "        # total loss\n",
        "        total_loss += loss.item()\n",
        "        # clip the norm of the gradients to 1.0.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        # update optimizer\n",
        "        optimizer.step()\n",
        "        # update learning rate \n",
        "        scheduler.step()    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    \n",
        "    print(\"average training loss: {0:.2f}\".format(avg_train_loss))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "envs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "6b16d1a6559efeda66307266d482d01ef10bc024de7015cc43e9f26f0fe94454"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
